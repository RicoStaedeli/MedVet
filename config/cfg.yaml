logging:
  level: DEBUG
  
model:
  name2: Meta-Llama-3-8B-Instruct-Q8_0
  name1: LLaMA-7b-chat
  name: Llama-2-7b-chat-medvet
  name3: Llama-3-8b-instruct-medvet
  _path: ../model/Llama-2-7b-chat.gguf
  _path: ../model/Meta-Llama-3-8B-Instruct-Q8_0.gguf
  _path: ../model/Llama-2-7b-chat-medvet.gguf
  _path: ../model/Llama-3-8b-instruct-medvet.gguf
  path: ../model/Llama-3-8b-instruct-medvet-2.gguf

LLM:
  temperature: 0.7
  max_tokens: 1096
  n_batch: 2048
  n_ctx: 4096

acceleration:
  useGPU: True
  GPU: mps 
  

RAG:
  source_path: ../Assets/RAG Documents/
  EMBEDDINGS_MODEL_NAME: all-MiniLM-L6-v2
  TARGET_SOURCE_CHUNKS: 4
  chunk_size: 500
  chunk_overlap: 50
